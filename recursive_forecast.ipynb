{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from feature_engine.datetime import DatetimeFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from feature_engine.encoding import MeanEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from feature_engine.imputation import (\n",
    "    ArbitraryNumberImputer,\n",
    "    CategoricalImputer,\n",
    "    MeanMedianImputer,\n",
    ")\n",
    "from feature_engine.selection import DropConstantFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sktime.transformations.series.summarize import WindowSummarizer\n",
    "from feature_engine.imputation import DropMissingData\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.timeseries.forecasting import WindowFeatures, LagFeatures\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\"holiday_name\"]\n",
    "NUMERICAL_COLUMNS = [\n",
    "    \"holiday\",\n",
    "    \"shutdown\",\n",
    "    \"mini_shutdown\",\n",
    "    \"shops_closed\",\n",
    "    \"winter_school_holidays\",\n",
    "    \"school_holidays\",\n",
    "    \"blackout\",\n",
    "    \"mov_change\",\n",
    "    \"frankfurt_shutdown\",\n",
    "    # \"date_year\",\n",
    "    # \"date_month\",\n",
    "    # \"date_day_of_month\",\n",
    "    # \"date_day_of_week\",\n",
    "    # \"date_day_of_year\",\n",
    "    # \"date_weekend\",\n",
    "]\n",
    "DATE_COLUMNS = [\"date\"]\n",
    "\n",
    "TARGET_COLUMNS = \"orders\"\n",
    "FEATRURE_COLUMNS = NUMERICAL_COLUMNS + CATEGORICAL_COLUMNS + DATE_COLUMNS\n",
    "TRAIN_LEVEL = [\"warehouse\"]\n",
    "MODEL_PATH = \"model_registry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "PATH = \"./data/\"\n",
    "df_train = pd.read_csv(f\"{PATH}train_new.csv\", parse_dates=[\"date\"])\n",
    "df_train[\"split\"] = \"train\"\n",
    "\n",
    "df_test = pd.read_csv(f\"{PATH}test_new.csv\", parse_dates=[\"date\"])\n",
    "df_test[\"split\"] = \"test\"\n",
    "\n",
    "cols = df_train.columns\n",
    "df_test = df_test[cols]\n",
    "\n",
    "df = pd.concat([df_train, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        # ('drop_na_lags', DropMissingData(variables=new_cols)),\n",
    "        # Impute missing categorical except mean-encoded ones, normally happens in the test data\n",
    "        (\n",
    "            \"missing_categoricals\",\n",
    "            CategoricalImputer(\n",
    "                imputation_method=\"missing\", variables=CATEGORICAL_COLUMNS\n",
    "            ),\n",
    "        ),\n",
    "        # Impute 0 for missing numericals\n",
    "        (\n",
    "            \"missing_numerical\",\n",
    "            ArbitraryNumberImputer(variables=NUMERICAL_COLUMNS, arbitrary_number=0),\n",
    "        ),\n",
    "        # OneHotEncode the rest of categorical\n",
    "        (\n",
    "            \"onehot_encoding\",\n",
    "            OneHotEncoder(\n",
    "                top_categories=6,\n",
    "                variables=CATEGORICAL_COLUMNS,\n",
    "                ignore_format=True,\n",
    "            ),\n",
    "        ),\n",
    "        # Drop Constant features\n",
    "        (\"drop_constant\", DropConstantFeatures(tol=1)),\n",
    "        # (\"xgb\", XGBRegressor(n_estimators=100, random_state=42)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lags = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"lag_window\",\n",
    "            # Create window features using the transformer.\n",
    "            WindowFeatures(\n",
    "                variables=[TARGET_COLUMNS],\n",
    "                functions=[\"mean\"],\n",
    "                window=[1, 7, 365],  # Day, week, year.\n",
    "                freq=\"D\",\n",
    "            ),\n",
    "        ),\n",
    "        (\"lag_features\", LagFeatures(variables=[TARGET_COLUMNS], periods=[1, 7, 365])),\n",
    "        # (\"drop_missing\", DropFeatures(features_to_drop=[TARGET_COLUMNS])),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_core_recursive(\n",
    "    df: pd.DataFrame,\n",
    "    train_level: list,\n",
    "    feature_columns: list,\n",
    "    target_column: str,\n",
    "    pipeline_lags: Pipeline,\n",
    "    pipeline: Pipeline,\n",
    "    model_dir: str = \"model_registry\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"This function run the train for a single level.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataframe including level columns, features, and target columns\n",
    "        train_level (list): training level i.e. `['warehouse', 'item_class']`\n",
    "        feature_columns (list): Feature columns.\n",
    "        target_column (str): traget columns should be a single string.\n",
    "        model_dir (str, optional): Name of the directory for saving the model pickel files. Defaults to \"model_registry\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A single row dataframe including the train level, model registry path, and error if we have any.\n",
    "    \"\"\"\n",
    "\n",
    "    e = \"\"\n",
    "\n",
    "    train_level_value = df[train_level].iloc[0, :].to_list()\n",
    "\n",
    "    try:\n",
    "        df2 = df.copy()\n",
    "        df2.set_index(\"date\", inplace=True)\n",
    "        df2 = pipeline_lags.fit_transform(df2)\n",
    "        df2.reset_index(inplace=True)\n",
    "\n",
    "        new_cols = [col for col in df2.columns if col not in df.columns]\n",
    "        df2.dropna(subset=new_cols, how=\"any\", inplace=True)\n",
    "\n",
    "        X = df2[feature_columns + new_cols]\n",
    "        y = df2[target_column]\n",
    "\n",
    "        model = pipeline.fit(X, y)\n",
    "\n",
    "        # saving the model to model registry\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        model_string = \"_\".join(\n",
    "            [f\"{a}_{b}\" for a, b in zip(train_level, train_level_value)]\n",
    "        )\n",
    "        model_path = os.path.join(model_dir, f\"model_{model_string}.pkl\")\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        model_path = \"\"\n",
    "\n",
    "    train_df = pd.DataFrame(\n",
    "        [train_level_value + [\"_\".join(train_level)] + [model_path] + [str(e)]],\n",
    "        columns=[*train_level, \"train_level\", \"model_path\", \"error\"],\n",
    "    )\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse = df_train[\"warehouse\"].unique()[6]\n",
    "_df = df_train.query(f\"warehouse== '{warehouse}'\").query(\n",
    "    f\"not {TARGET_COLUMNS}.isnull()\"\n",
    ")\n",
    "_df2 = df_test.query(f\"warehouse== '{warehouse}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse</th>\n",
       "      <th>train_level</th>\n",
       "      <th>model_path</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budapest_1</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>model_registry\\model_warehouse_Budapest_1.pkl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    warehouse train_level                                     model_path error\n",
       "0  Budapest_1   warehouse  model_registry\\model_warehouse_Budapest_1.pkl      "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_core_recursive(\n",
    "    _df,\n",
    "    TRAIN_LEVEL,\n",
    "    FEATRURE_COLUMNS,\n",
    "    TARGET_COLUMNS,\n",
    "    pipeline_lags,\n",
    "    pipeline,\n",
    "    model_dir=MODEL_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse</th>\n",
       "      <th>train_level</th>\n",
       "      <th>model_path</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brno_1</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>model_registry\\model_warehouse_Brno_1.pkl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Budapest_1</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>model_registry\\model_warehouse_Budapest_1.pkl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frankfurt_1</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>model_registry\\model_warehouse_Frankfurt_1.pkl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Munich_1</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>model_registry\\model_warehouse_Munich_1.pkl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prague_1</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>model_registry\\model_warehouse_Prague_1.pkl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prague_2</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>model_registry\\model_warehouse_Prague_2.pkl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Prague_3</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>model_registry\\model_warehouse_Prague_3.pkl</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     warehouse train_level                                      model_path  \\\n",
       "0       Brno_1   warehouse       model_registry\\model_warehouse_Brno_1.pkl   \n",
       "1   Budapest_1   warehouse   model_registry\\model_warehouse_Budapest_1.pkl   \n",
       "2  Frankfurt_1   warehouse  model_registry\\model_warehouse_Frankfurt_1.pkl   \n",
       "3     Munich_1   warehouse     model_registry\\model_warehouse_Munich_1.pkl   \n",
       "4     Prague_1   warehouse     model_registry\\model_warehouse_Prague_1.pkl   \n",
       "5     Prague_2   warehouse     model_registry\\model_warehouse_Prague_2.pkl   \n",
       "6     Prague_3   warehouse     model_registry\\model_warehouse_Prague_3.pkl   \n",
       "\n",
       "  error  \n",
       "0        \n",
       "1        \n",
       "2        \n",
       "3        \n",
       "4        \n",
       "5        \n",
       "6        "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.query(f\"not {TARGET_COLUMNS}.isnull()\").groupby(TRAIN_LEVEL).apply(\n",
    "    train_model_core_recursive,\n",
    "    TRAIN_LEVEL,\n",
    "    FEATRURE_COLUMNS,\n",
    "    TARGET_COLUMNS,\n",
    "    pipeline_lags,\n",
    "    pipeline,\n",
    "    model_dir=MODEL_PATH,\n",
    "    include_groups=True,\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
